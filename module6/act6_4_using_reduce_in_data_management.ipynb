{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1375f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting more-pyspark\n",
      "  Downloading more_pyspark-0.1.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: more-itertools<10.0.0,>=9.0.0 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from more-pyspark) (9.0.0)\n",
      "Requirement already satisfied: pyspark<4,>=3 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from more-pyspark) (3.3.1)\n",
      "Requirement already satisfied: pandas<2,>=1 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from more-pyspark) (1.4.2)\n",
      "Collecting composable>=0.4.0\n",
      "  Downloading composable-0.4.0-py3-none-any.whl (5.1 kB)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from composable>=0.4.0->more-pyspark) (18.6.0)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from composable>=0.4.0->more-pyspark) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pandas<2,>=1->more-pyspark) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pandas<2,>=1->more-pyspark) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pandas<2,>=1->more-pyspark) (1.21.5)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from pyspark<4,>=3->more-pyspark) (0.10.9.5)\n",
      "Requirement already satisfied: six>=1.5 in ./.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas<2,>=1->more-pyspark) (1.16.0)\n",
      "Installing collected packages: composable, more-pyspark\n",
      "  Attempting uninstall: composable\n",
      "    Found existing installation: composable 0.2.5\n",
      "    Uninstalling composable-0.2.5:\n",
      "      Successfully uninstalled composable-0.2.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "more-dfply 0.2.10 requires composable<0.3.0,>=0.2.5, but you have composable 0.4.0 which is incompatible.\u001b[0m\n",
      "Successfully installed composable-0.4.0 more-pyspark-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install more-pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e6204",
   "metadata": {},
   "source": [
    "# Using `reduce` in data management.\n",
    "\n",
    "There are two common tasks that can be solved using `reduce`.\n",
    "\n",
    "1. Dot-chaining/piping similar actions.\n",
    "2. Any many-to-one operation like UNION or JOIN on many files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de533101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/04 15:01:49 WARN Utils: Your hostname, jt7372wd222 resolves to a loopback address: 127.0.1.1; using 172.30.75.123 instead (on interface eth0)\n",
      "22/11/04 15:01:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/04 15:01:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Ops').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a8123",
   "metadata": {},
   "source": [
    "## Example 1 - Transforming the eagle data\n",
    "\n",
    "In a previous activity, we had to perform similar transformations on many columns.  In `pyspark` this can be accomplished using many similar mutates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de18030c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/home/fahad/module-6-lectures-nameer1811/data/bald_eagle_subsample.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/fahad/activity-6-4-using-reduce-in-data-management-nameer1811-1/act6_4_using_reduce_in_data_management.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/fahad/activity-6-4-using-reduce-in-data-management-nameer1811-1/act6_4_using_reduce_in_data_management.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmore_pyspark\u001b[39;00m \u001b[39mimport\u001b[39;00m to_pandas\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/fahad/activity-6-4-using-reduce-in-data-management-nameer1811-1/act6_4_using_reduce_in_data_management.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m eagle \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mcsv(\u001b[39m'\u001b[39;49m\u001b[39m./data/bald_eagle_subsample.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, inferSchema\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/fahad/activity-6-4-using-reduce-in-data-management-nameer1811-1/act6_4_using_reduce_in_data_management.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m eagle\u001b[39m.\u001b[39mtake(\u001b[39m2\u001b[39m) \u001b[39m>>\u001b[39m to_pandas\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/pyspark/sql/readwriter.py:535\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spark\u001b[39m.\u001b[39m_sc\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 535\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mcsv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spark\u001b[39m.\u001b[39;49m_sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonUtils\u001b[39m.\u001b[39;49mtoSeq(path)))\n\u001b[1;32m    536\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    538\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/home/fahad/module-6-lectures-nameer1811/data/bald_eagle_subsample.csv"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from more_pyspark import to_pandas\n",
    "\n",
    "eagle = spark.read.csv('./data/bald_eagle_subsample.csv', header=True, inferSchema=True)\n",
    "\n",
    "eagle.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df6bc28",
   "metadata": {},
   "source": [
    "#### Applying the `sqrt` transform with many `withColumn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e25b0fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>sqrt_KPH</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>5.728001</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.443345</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  sqrt_KPH   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  \\\n",
       "0   0.006277  0.002167  5.728001  2.624881   0.141421        0.079229   \n",
       "1   0.570000  0.120000  5.443345  2.791057   0.000000        0.754983   \n",
       "\n",
       "   sqrt_absVR  \n",
       "0    0.046548  \n",
       "1    0.346410  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sqrt\n",
    "\n",
    "(eagle\n",
    ".withColumn('sqrt_KPH', sqrt(col('KPH')))\n",
    ".withColumn('sqrt_Sn', sqrt(col('Sn')))\n",
    ".withColumn('sqrt_AGL0', sqrt(col('AGL0')))\n",
    ".withColumn('sqrt_abs_angle', sqrt(col('abs_angle')))\n",
    ".withColumn('sqrt_absVR', sqrt(col('absVR')))\n",
    ").take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f0847",
   "metadata": {},
   "source": [
    "#### Rewritten using the accumulator pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7a88ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>sqrt_KPH</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>5.728001</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.443345</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  sqrt_KPH   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  \\\n",
       "0   0.006277  0.002167  5.728001  2.624881   0.141421        0.079229   \n",
       "1   0.570000  0.120000  5.443345  2.791057   0.000000        0.754983   \n",
       "\n",
       "   sqrt_absVR  \n",
       "0    0.046548  \n",
       "1    0.346410  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_pyspark import cols_from\n",
    "from composable.strict import filter\n",
    "\n",
    "measurements = eagle.columns >> cols_from('KPH')\n",
    "sqrt_cols = measurements >> filter(lambda col: col != 'VerticalRate')\n",
    "\n",
    "df = eagle\n",
    "for c in sqrt_cols:\n",
    "    df = df.withColumn('sqrt_' + c, sqrt(col(c)))\n",
    "df.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e517be61",
   "metadata": {},
   "source": [
    "#### Refactored using `reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7df0266e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>sqrt_KPH</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>5.728001</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>5.443345</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  sqrt_KPH   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  \\\n",
       "0   0.006277  0.002167  5.728001  2.624881   0.141421        0.079229   \n",
       "1   0.570000  0.120000  5.443345  2.791057   0.000000        0.754983   \n",
       "\n",
       "   sqrt_absVR  \n",
       "0    0.046548  \n",
       "1    0.346410  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from composable.sequence import reduce\n",
    "\n",
    "add_sqrt = lambda df, c: df.withColumn('sqrt_' + c, sqrt(col(c)))\n",
    "\n",
    "eagle_w_sqrt = reduce(add_sqrt, sqrt_cols, eagle)\n",
    "\n",
    "eagle_w_sqrt.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c72e0",
   "metadata": {},
   "source": [
    "## Example 2 - Performing a UNION on more than 2 files.\n",
    "\n",
    "The other common task solved by `reduce` is combination many files using verbs such as UNION or JOIN.  We will illustrate by combining the `./data/uber*.csv` files, which are sample of the [538 Uber TLC FOIL data](https://github.com/fivethirtyeight/uber-tlc-foil-response).\n",
    "\n",
    "Furthermore, we will illustrate using a pipe to perform the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4d04f",
   "metadata": {},
   "source": [
    "#### Step 1 - Make `pipeable`/helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a976d0",
   "metadata": {},
   "source": [
    "#### A pipeable glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2a02fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/uber-raw-data-jun14-sample.csv',\n",
       " './data/uber-raw-data-may14-sample.csv',\n",
       " './data/uber-raw-data-aug14-sample.csv',\n",
       " './data/uber-raw-data-sep14-sample.csv',\n",
       " './data/uber-raw-data-apr14-sample.csv',\n",
       " './data/uber-raw-data-jul14-sample.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob as original_glob\n",
    "from composable import pipeable\n",
    "\n",
    "glob = pipeable(original_glob)\n",
    "\n",
    "('./data/uber*.csv' \n",
    " >> glob\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a880b3",
   "metadata": {},
   "source": [
    "#### a `read_csv` helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d519dd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-19 16:49:00</td>\n",
       "      <td>40.7568</td>\n",
       "      <td>-73.9701</td>\n",
       "      <td>B02682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-12 21:25:00</td>\n",
       "      <td>40.6463</td>\n",
       "      <td>-73.7768</td>\n",
       "      <td>B02598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date/Time      Lat      Lon    Base\n",
       "0 2014-06-19 16:49:00  40.7568 -73.9701  B02682\n",
       "1 2014-06-12 21:25:00  40.6463 -73.7768  B02598"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from more_pyspark import pprint_schema\n",
    "from uber_schema import uber_datetime_format, uber_schema\n",
    "\n",
    "read_uber_csv = lambda path: spark.read.csv(path, header=True, schema=uber_schema, timestampFormat=uber_datetime_format)\n",
    "\n",
    "read_uber_csv('./data/uber-raw-data-jun14-sample.csv').take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fae7525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType([StructField('Date/Time', TimestampType(), True),\n",
      "            StructField('Lat', DoubleType(), True),\n",
      "            StructField('Lon', DoubleType(), True),\n",
      "            StructField('Base', StringType(), True)])\n"
     ]
    }
   ],
   "source": [
    "read_uber_csv('./data/uber-raw-data-jun14-sample.csv') >> pprint_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e340194d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string],\n",
       " DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from composable.strict import map\n",
    "\n",
    "uber_dfs = ('./data/uber*.csv' \n",
    "             >> glob\n",
    "             >> map(read_uber_csv)\n",
    "            )\n",
    "\n",
    "uber_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca60a77",
   "metadata": {},
   "source": [
    "### Brute-force solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45dc4554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-19 16:49:00</td>\n",
       "      <td>40.7568</td>\n",
       "      <td>-73.9701</td>\n",
       "      <td>B02682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-12 21:25:00</td>\n",
       "      <td>40.6463</td>\n",
       "      <td>-73.7768</td>\n",
       "      <td>B02598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date/Time      Lat      Lon    Base\n",
       "0 2014-06-19 16:49:00  40.7568 -73.9701  B02682\n",
       "1 2014-06-12 21:25:00  40.6463 -73.7768  B02598"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_dfs[0]\n",
    " .union(uber_dfs[1])\n",
    " .union(uber_dfs[2])\n",
    " .union(uber_dfs[3])\n",
    " .union(uber_dfs[4])\n",
    " .union(uber_dfs[5])\n",
    ").take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476278db",
   "metadata": {},
   "source": [
    "### Using the accumulator pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94b7c420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-19 16:49:00</td>\n",
       "      <td>40.7568</td>\n",
       "      <td>-73.9701</td>\n",
       "      <td>B02682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-12 21:25:00</td>\n",
       "      <td>40.6463</td>\n",
       "      <td>-73.7768</td>\n",
       "      <td>B02598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date/Time      Lat      Lon    Base\n",
       "0 2014-06-19 16:49:00  40.7568 -73.9701  B02682\n",
       "1 2014-06-12 21:25:00  40.6463 -73.7768  B02598"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = uber_dfs[0]\n",
    "for df in uber_dfs[1:]:\n",
    "    output_df.union(df)\n",
    "output_df.take(2) >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728f9220",
   "metadata": {},
   "source": [
    "### Refactored using `reduce`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e32d4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(uber_dfs\n",
    " >> reduce(lambda out_df, df: out_df.union(df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db5965",
   "metadata": {},
   "source": [
    "#### Click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da16da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date/Time: timestamp, Lat: double, Lon: double, Base: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('./data/uber*.csv' \n",
    " >> glob\n",
    " >> map(read_uber_csv)\n",
    " >> reduce(lambda out_df, df: out_df.union(df))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bff7a",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Exercise 1 </font>\n",
    "\n",
    "Use `reduce` to mean-center and standardize the `sqrt` column, as well as `VerticalRate`, in the eagle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c05dbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/03 12:37:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:37:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:37:49 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:37:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/11/03 12:37:50 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Animal_ID</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age2</th>\n",
       "      <th>LocalTime</th>\n",
       "      <th>KPH</th>\n",
       "      <th>Sn</th>\n",
       "      <th>AGL0</th>\n",
       "      <th>VerticalRate</th>\n",
       "      <th>abs_angle</th>\n",
       "      <th>absVR</th>\n",
       "      <th>...</th>\n",
       "      <th>sqrt_Sn</th>\n",
       "      <th>sqrt_AGL0</th>\n",
       "      <th>sqrt_abs_angle</th>\n",
       "      <th>sqrt_absVR</th>\n",
       "      <th>z_score_sqrt_KPH</th>\n",
       "      <th>z_score_sqrt_Sn</th>\n",
       "      <th>z_score_sqrt_AGL0</th>\n",
       "      <th>z_score_sqrt_abs_angle</th>\n",
       "      <th>z_score_sqrt_absVR</th>\n",
       "      <th>z_score_VerticalRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>...</td>\n",
       "      <td>2.624881</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.079229</td>\n",
       "      <td>0.046548</td>\n",
       "      <td>-0.672224</td>\n",
       "      <td>-0.957445</td>\n",
       "      <td>-1.874878</td>\n",
       "      <td>-1.697594</td>\n",
       "      <td>-2.083444</td>\n",
       "      <td>0.024918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>Fledgling</td>\n",
       "      <td>7/4/19 9:01</td>\n",
       "      <td>29.63</td>\n",
       "      <td>7.79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.120000</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.791057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754983</td>\n",
       "      <td>0.346410</td>\n",
       "      <td>-0.920741</td>\n",
       "      <td>-0.712885</td>\n",
       "      <td>-1.895064</td>\n",
       "      <td>-0.356132</td>\n",
       "      <td>-1.394379</td>\n",
       "      <td>-0.057365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Animal_ID Sex       Age2    LocalTime    KPH    Sn  AGL0  VerticalRate  \\\n",
       "0        105   F  Fledgling  7/4/19 9:01  32.81  6.89  0.02     -0.002167   \n",
       "1        105   F  Fledgling  7/4/19 9:01  29.63  7.79  0.00     -0.120000   \n",
       "\n",
       "   abs_angle     absVR  ...   sqrt_Sn  sqrt_AGL0  sqrt_abs_angle  sqrt_absVR  \\\n",
       "0   0.006277  0.002167  ...  2.624881   0.141421        0.079229    0.046548   \n",
       "1   0.570000  0.120000  ...  2.791057   0.000000        0.754983    0.346410   \n",
       "\n",
       "   z_score_sqrt_KPH  z_score_sqrt_Sn  z_score_sqrt_AGL0  \\\n",
       "0         -0.672224        -0.957445          -1.874878   \n",
       "1         -0.920741        -0.712885          -1.895064   \n",
       "\n",
       "   z_score_sqrt_abs_angle  z_score_sqrt_absVR  z_score_VerticalRate  \n",
       "0               -1.697594           -2.083444              0.024918  \n",
       "1               -0.356132           -1.394379             -0.057365  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code there\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "from more_pyspark import *\n",
    "\n",
    "w = Window.partitionBy()\n",
    "col_mean = lambda c: mean(col(c)).over(w)\n",
    "std_dev = lambda c: stddev(col(c)).over(w)\n",
    "z_score = lambda c: (col(c) - col_mean(c))/std_dev(c)\n",
    "z_score_acc = lambda df, c: df.withColumn('z_score_'+c, z_score(c))\n",
    "\n",
    "z_score_cols = eagle_w_sqrt.columns >> cols_from('sqrt_KPH')\n",
    "z_score_cols.append('VerticalRate')\n",
    "\n",
    "eagle_standardized = reduce(z_score_acc, z_score_cols, eagle_w_sqrt)\n",
    "eagle_standardized.take(2) >> to_pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7aeea",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Exercise 2 </font>\n",
    "\n",
    "In all of my class, I use an attendance quiz to track student attendance.  In previous semesters, I reused the same quiz each day and students take multiple attempts at the same quiz, one per class; so that number of attempts a student takes on this quiz represents the number of class session that student has attended.\n",
    "\n",
    "In some, but not all, of my courses I also provide practice quizzes that students can use to prepare for actual quizzes and tests.  **In this example, you should ignore these CSV files.** \n",
    "\n",
    "In this exercise, you will combine (simulated) attendance data from my (mock) classes into one summary table.\n",
    "\n",
    "#### Tasks \n",
    "\n",
    "The files found in the `./data/attendance_example` sub-folders contains (made-up and random) examples of the D2L files that I use to summarize my attendance quizzes and practice quizzes\n",
    "\n",
    "1. Use `glob` to find the path to all *attendance* CSV files.\n",
    "2. Write following helper function that takes a path and use regular expressions to extract the class name and the module number, combining and returning both in a single output string.\n",
    "3. Write a function that task a path, reads in the corresponding CSV, and adds a `Class/Section` column containing the relevant entry for that table.  Be sure to test this on one of the paths found in **1.**.\n",
    "4. Write a pipe that \n",
    "    1. Starts with the `glob` search string.\n",
    "    2. Uses `glob` to find all paths.\n",
    "    3. Maps your function from **3.** onto all the paths.\n",
    "    4. Uses reduce to UNION the files into one master data frame.\n",
    "5. Create a summary table that shows the 10 worst students in terms of attendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
